# ANISE Context for LLMs

ANISE is a high-fidelity astrodynamics library written in Rust with Python bindings.

## General Directives

1.  **Time Calculations**: Always rely on `hifitime` for all time calculations. Use `Epoch` and `Duration` types from `hifitime` (or `anise.time` in Python).
2.  **Units**: Use `Unit` for all unit conversions. Do not hardcode conversion factors.
3.  **Iteration**: Use `TimeSeries` for iterating over time steps.
4.  **Dependencies**:
    - The project depends on `cspice`. Ensure `CSPICE_DIR` is set for tests involving SPICE.
    - Rust feature flags like `python` and `analysis` may be needed for certain functionalities.

---

## Rust Section

The Rust crate is the core of ANISE.

### Example: State Transformation

Below is an example of loading an Almanac, creating an Orbit, and transforming it between frames.

```rust
use anise::{
    constants::frames::{EARTH_ITRF93, EARTH_J2000, SUN_J2000},
    naif::kpl::parser::convert_tpc,
    prelude::{Aberration, Almanac, Orbit, BPC, SPK},
};
use core::str::FromStr;
use hifitime::Epoch;

#[test]
fn test_state_transformation() {
    // Load BSP and BPC
    let ctx = Almanac::default();

    let spk = SPK::load("../data/de440.bsp").unwrap();
    let bpc = BPC::load("../data/earth_latest_high_prec.bpc").unwrap();

    let almanac = ctx
        .with_spk(spk)
        .with_bpc(bpc)
        .load("../data/pck08.pca")
        .unwrap();
    // Let's build an orbit
    // Start by grabbing a copy of the frame.
    let eme2k = almanac.frame_info(EARTH_J2000).unwrap();
    // Define an epoch
    let epoch = Epoch::from_str("2021-10-29 12:34:56 TDB").unwrap();

    let orig_state = Orbit::keplerian(
        8_191.93, 1e-6, 12.85, 306.614, 314.19, 99.887_7, epoch, eme2k,
    );

    // Transform that into another frame.
    let state_itrf93 = almanac
        .transform_to(orig_state, EARTH_ITRF93, Aberration::NONE)
        .unwrap();

    // Check that the frame is correctly set.
    assert_eq!(state_itrf93.frame.ephemeris_id, EARTH_ITRF93.ephemeris_id);
    assert_eq!(
        state_itrf93.frame.orientation_id,
        EARTH_ITRF93.orientation_id
    );

    println!("{orig_state:x}");
    println!("{state_itrf93:X}");

    // Convert back.
    // Note that the Aberration correction constants are actually options!
    let from_state_itrf93_to_eme2k = almanac
        .transform_to(state_itrf93, EARTH_J2000, None)
        .unwrap();

    println!("{from_state_itrf93_to_eme2k}");
    println!("{from_state_itrf93_to_eme2k:x}");

    assert_eq!(orig_state, from_state_itrf93_to_eme2k);
}
```

---

## Python Section

Most users are expected to use ANISE via its Python bindings (`anise` package).

### Examples

The following are test files from `anise-py/tests/` which demonstrate the usage of the Python API.

#### `anise-py/tests/test_almanac.py`

```python
import os
from pathlib import Path
import pickle
from math import radians

from anise import (
    Almanac,
    MetaAlmanac,
    MetaFile,
    LocationDataSet,
    LocationDhallSet,
    LocationDhallSetEntry,
)
from anise.analysis import OrbitalElement
from anise.astro import *
from anise.constants import Frames
from anise.rotation import DCM, Quaternion
from anise.time import Duration, Epoch, TimeSeries, Unit
from anise.utils import convert_tpc

import numpy as np
from os import environ


def test_state_transformation():
    """
    This is the Python equivalent to anise/tests/almanac/mod.rs
    but the data is loaded from the remote servers
    """

    data_path = Path(__file__).parent.joinpath("..", "..", "data")
    # Must ensure that the path is a string
    almanac = Almanac(str(data_path.joinpath("de440s.bsp")))
    # Let's add another file here -- note that the Almanac will load into a NEW variable, so we must overwrite it!
    # This prevents memory leaks (yes, I promise)
    almanac = almanac.load(str(data_path.joinpath("pck08.pca"))).load(
        str(data_path.joinpath("earth_latest_high_prec.bpc"))
    )

    eme2k = almanac.frame_info(Frames.EME2000)
    assert eme2k.mu_km3_s2() == 398600.435436096
    assert eme2k.shape.polar_radius_km == 6356.75
    assert abs(eme2k.shape.flattening() - 0.0033536422844278) < 2e-16

    epoch = Epoch("2021-10-29 12:34:56 TDB")

    orig_state = Orbit.from_keplerian(
        8_191.93,
        1e-6,
        12.85,
        306.614,
        314.19,
        99.887_7,
        epoch,
        eme2k,
    )

    print(f"SMA: {orig_state.sma_km()} km")
    print(f"Eccentricity: {orig_state.ecc()}")
    print(f"Inclination: {orig_state.inc_deg()} deg")
    print(f"RAAN: {orig_state.raan_deg()} deg")
    print(f"True Longitude: {orig_state.tlong_deg()} deg")

    assert orig_state.cartesian_pos_vel().shape == (6,)

    # Ensure we can call all of the DCM functions
    for func in [
        "dcm_from_ric_to_inertial",
        "dcm_from_rcn_to_inertial",
        "dcm_from_vnc_to_inertial",
    ]:
        dcm = getattr(orig_state, func)()
        assert dcm.get_state_dcm().shape == (6, 6)
        assert dcm.rot_mat.shape == (3, 3)
        assert dcm.rot_mat_dt.shape == (3, 3)
        print(f"== {func} ==\n{dcm}")
        # Test rebuilding the DCM from its parts
        dcm_rebuilt = DCM(dcm.rot_mat, dcm.from_id, dcm.to_id, dcm.rot_mat_dt)
        assert dcm_rebuilt == dcm

    # Check that we can convert a DCM to a quaternion and back
    q = dcm.to_quaternion()
    q_rebuilt = Quaternion(q.w, q.x, q.y, q.z, q.from_id, q.to_id)

    uvec, angle = q.uvec_angle_rad()
    prv = q.prv()
    err = angle * uvec - prv
    assert sum([e**2 for e in err]) < 2e-16
    dcm_from_q = q.to_dcm()
    assert q.b_matrix().shape == (4, 3)

    orig_uvec, orig_angle_rad = q.uvec_angle_rad()
    rtn_uvec, rtn_angle_rad = dcm_from_q.to_quaternion().uvec_angle_rad()

    assert all(rtn_uvec == orig_uvec)
    assert rtn_angle_rad == orig_angle_rad

    topo_dcm = orig_state.dcm_from_topocentric_to_body_fixed()
    assert topo_dcm.get_state_dcm().shape == (6, 6)
    assert topo_dcm.rot_mat.shape == (3, 3)
    assert (
        topo_dcm.rot_mat_dt is not None and topo_dcm.rot_mat_dt.shape == (3, 3)
    ) or topo_dcm.rot_mat_dt is None

    # In Python, we can set the aberration to None
    aberration = None

    state_itrf93 = almanac.transform_to(orig_state, Frames.EARTH_ITRF93, aberration)

    print(orig_state)
    print(state_itrf93)

    assert abs(state_itrf93.latitude_deg() - 10.549246868302738) < 1e-10
    assert abs(state_itrf93.longitude_deg() - 133.76889100913047) < 1e-10
    assert abs(state_itrf93.height_km() - 1814.503598063825) < 1e-10

    # Convert back
    from_state_itrf93_to_eme2k = almanac.transform_to(state_itrf93, Frames.EARTH_J2000)

    print(from_state_itrf93_to_eme2k)

    assert orig_state == from_state_itrf93_to_eme2k

    # Demo creation of a ground station
    mean_earth_angular_velocity_deg_s = 0.004178079012116429
    # Grab the loaded frame info
    itrf93 = almanac.frame_info(Frames.EARTH_ITRF93)
    paris = Orbit.from_latlongalt(
        48.8566,
        2.3522,
        0.4,
        epoch,
        itrf93,
    )

    assert abs(paris.latitude_deg() - 48.8566) < 1e-3
    assert abs(paris.longitude_deg() - 2.3522) < 1e-3
    assert abs(paris.height_km() - 0.4) < 1e-3

    # Lat/long/alt high fidelity
    omega_itrf93 = almanac.angular_velocity_wrt_j2000_rad_s(Frames.EARTH_ITRF93, epoch)
    paris_prec = Orbit.from_latlongalt_omega(
        48.8566,
        2.3522,
        0.4,
        omega_itrf93,
        epoch,
        itrf93,
    )

    assert abs(paris_prec.latitude_deg() - 48.8566) < 1e-3
    assert abs(paris_prec.longitude_deg() - 2.3522) < 1e-3
    assert abs(paris_prec.height_km() - 0.4) < 1e-3
    # Test that the velocity for the high precision is correct.
    # Assume that the ITRF Z is the main axis of rotation, so there should not be much velocity there
    assert paris_prec.vz_km_s < 1e-3
    # Compute the perpendicular distance of the object
    r_perp_km = (paris_prec.x_km**2 + paris_prec.y_km**2) ** 0.5
    # Speed of that point based on its distance from the center of Earth
    speed_km_s = r_perp_km * radians(mean_earth_angular_velocity_deg_s)

    # Check the approximation of the mean angular velocity is correct.
    assert abs(speed_km_s - paris_prec.vmag_km_s()) < 1e-3

    # Pickling test
    pickle.loads(pickle.dumps(eme2k)) == eme2k
    pickle.loads(pickle.dumps(eme2k.shape)) == eme2k.shape
    # Cannot pickle across module boundaries =(
    # pickle.loads(pickle.dumps(paris)) == paris

    # Test that we can get the SPK data type
    assert int(almanac.spk_summaries(301)[0].datatype()) == 2, "not shown as type 2"

    # Function export test
    for fname in [
        "transform",
        "transform_to",
        "translate",
        "translate_to",
        "translate_geometric",
        "spk_ezr",
        "state_of",
        "solar_eclipsing",
        "occultation",
        "line_of_sight_obstructed",
        "azimuth_elevation_range_sez",
        "spk_domains",
        "spk_summaries",
    ]:
        assert hasattr(almanac, fname)

    # Test the parallel function calls
    start = Epoch("2021-10-29 12:34:56 TDB")
    stop = Epoch("2022-10-29 12:34:56 TDB")
    time_series = TimeSeries(
        start,
        stop,
        Duration("1 min"),
        False,
    )

    tick = Epoch.system_now()

    states = almanac.transform_many(
        Frames.EARTH_J2000,
        Frames.SUN_J2000,
        time_series,
        None,
    )

    clock_time = Epoch.system_now().timedelta(tick)
    print(f"Queried {len(states)} states in {clock_time}")
    assert len(states) == int(stop.timedelta(start).to_unit(Unit.Minute))


def test_numpy_constructor():
    if environ.get("CI", False):
        # Load from meta kernel to not use Git LFS quota
        data_path = Path(__file__).parent.joinpath(
            "..", "..", "data", "ci_config.dhall"
        )
        meta = MetaAlmanac(str(data_path))
        almanac = meta.process()
    else:
        data_path = Path(__file__).parent.joinpath("..", "..", "data")
        almanac = Almanac(str(data_path.joinpath("pck08.pca")))

    epoch = Epoch("2021-10-29 12:34:56 TDB")
    eme2k = almanac.frame_info(Frames.EME2000)

    state_vector = np.array([8_191.93, 0.0, 0.0, 0.0, 7.6, 0.0])

    orbit_from_npy = Orbit(state_vector, epoch, eme2k)

    orbit_from_floats = Orbit(8_191.93, 0.0, 0.0, 0.0, 7.6, 0.0, epoch, eme2k)

    assert orbit_from_npy == orbit_from_floats

    # Test that it fails with a wrong-sized array
    with np.testing.assert_raises(ValueError):
        Orbit(np.array([1.0, 2.0, 3.0]), epoch, eme2k)

    assert np.all(orbit_from_npy.radius_km() == np.array([8_191.93, 0.0, 0.0]))
    assert np.all(orbit_from_npy.velocity_km_s() == np.array([0.0, 7.6, 0.0]))


def test_convert_tpc():
    """Attempt to reproduce GH issue #339"""
    try:
        os.remove("test_constants.tpc")
    except FileNotFoundError:
        pass

    # First call to convert_tpc works
    convert_tpc("data/pck00011.tpc", "data/gm_de440.tpc", "test_constants.tpc")

    # Second call, with overwrite enabled, also works
    convert_tpc(
        "data/pck00011.tpc", "data/gm_de440.tpc", "test_constants.tpc", overwrite=True
    )

    # Try to load the constants file
    constants_file = MetaFile("test_constants.tpc")
    new_meta = MetaAlmanac()
    new_meta.files = [
        constants_file,
    ]
    almanac = new_meta.process()

    earth_j2k = almanac.frame_info(Frames.EARTH_J2000)
    assert earth_j2k.mu_km3_s2 is not None
    almanac.describe()


def test_meta_load():
    data_path = Path(__file__).parent.joinpath("..", "..", "data", "local.dhall")
    meta = MetaAlmanac(str(data_path))
    print(meta)
    try:
        # Process the files to be loaded
        almanac = meta.process()
    except Exception as e:
        print("Not sure where the files are on Github CI")
        print(e)
    else:
        # And check that everything is loaded
        eme2k = almanac.frame_info(Frames.EME2000)
        assert eme2k.mu_km3_s2() == 398600.435436096
        assert eme2k.shape.polar_radius_km == 6356.75
        assert abs(eme2k.shape.flattening() - 0.0033536422844278) < 2e-16


def test_exports():
    for cls in [Frame, Ellipsoid, Orbit]:
        print(f"{cls} OK")


def test_frame_defs():
    print(f"{Frames.SSB_J2000}")
    print(dir(Frames))
    assert Frames.EME2000 == Frames.EME2000
    assert Frames.EME2000 == Frames.EARTH_J2000
    assert Frames.EME2000 != Frames.SSB_J2000


def test_location():
    mask = [TerrainMask(0.0, 5.0), TerrainMask(35.0, 10.0), TerrainMask(270.0, 3.0)]
    dss65 = Location(
        40.427_222,
        4.250_556,
        0.834_939,
        FrameUid(399, 399),
        mask,
        terrain_mask_ignored=False,
    )

    as_dhall = dss65.to_dhall()

    from_dhall = Location.from_dhall(as_dhall)

    print(from_dhall)

    # To build a location data set kernel, we must first build a location dhall set entry
    entry = LocationDhallSetEntry(dss65, id=1, alias="My Alias")
    # Then we append it to a LocationDhallSet
    dhallset = LocationDhallSet([entry])
    assert "data" in dir(dhallset), "missing getting on dhall set"
    # Now, we can build the kernel
    dataset = dhallset.to_dataset()
    # Save it as a Location Kernel ANISE (LKA) file, overwritting it if it exists
    dataset.save_as("pytest_loc_kernel.lka", True)
    # Reload it
    reloaded = LocationDataSet.load("pytest_loc_kernel.lka")
    # We can also convert it its Dhall representation
    dhallset = reloaded.to_dhallset()
    print(dhallset.to_dhall())
    # Confirm that we can load it in the almanac.
    almanac = Almanac("pytest_loc_kernel.lka")
    # Recall: the describe has its own print!
    almanac.describe()
    # And we can grab the location data itself
    my_loc = dhallset.data[0]
    print(my_loc.alias)
    print(my_loc.value)  # This is the location info
    terrain_mask = my_loc.value.terrain_mask
    print(terrain_mask)


def test_version():
    from anise import __version__

    assert __version__ is not None


def test_oem():
    # Load an Almanac for the various frames used here.
    almanac = Almanac("data/pck11.pca")
    # 1. Load an OEM to Ephem
    ephem = Ephemeris.from_ccsds_oem_file("data/tests/ccsds/oem/LRO_Nyx.oem")
    print(ephem)
    assert ephem.degree == 7, f"Expected degree 7, got {ephem.degree}"
    (start, end) = ephem.domain()
    # Query the covariance using the Log Euclidean method
    covar = ephem.covar_at(start + (end - start) * 0.5, LocalFrame.RIC, almanac)
    print(covar)
    covar = ephem.covar_at(start + (end - start) * 0.5, LocalFrame.Inertial, almanac)
    print(covar)
    covar = ephem.covar_at(start + (end - start) * 0.5, LocalFrame.RCN, almanac)
    print(covar)
    covar = ephem.covar_at(start + (end - start) * 0.5, LocalFrame.VNC, almanac)
    print(covar)
    # Export to SPICE BSP
    ephem.write_spice_bsp(
        -159,
        "data/tests/naif/spk/ephem_from_python.bsp",
        DataType.Type13HermiteUnequalStep,
    )
    # Export to CCSDS OEM
    ephem.write_ccsds_oem(
        "data/tests/naif/spk/ephem_from_python.oem", "My Originator", "OBJECT_NAME"
    )
    # Ensure we can read what we wrote
    ephem_reread = Ephemeris.from_ccsds_oem_file(
        "data/tests/naif/spk/ephem_from_python.oem"
    )
    assert ephem_reread.start_epoch() == ephem.start_epoch()
    assert ephem_reread.end_epoch() == ephem.end_epoch()

    # 2. Load OEM to new Almanac, providing an ID to convert this OEM to SPK
    almanac2 = Almanac.from_ccsds_oem_file("data/tests/ccsds/oem/LRO_Nyx.oem", -159)
    start2, end2 = almanac2.spk_domain(-159)
    # Small difference due to Ephemeris Time conversion, cf. hifitime docs
    assert (start2 - start).abs().to_seconds() < 1e-7
    assert (end2 - end).abs().to_seconds() < 1e-7
    # 3. Load OEM to existing almanac
    almanac = almanac.load_ccsds_oem_file("data/tests/ccsds/oem/LRO_Nyx.oem", -160)
    start3, end3 = almanac.spk_domain(-160)
    assert start2 == start3
    assert end2 == end3
    print(end3.to_et_seconds())
    # Compute the standard deviation for the covariance
    sigma_sma_km = ephem.at(end, almanac).sigma_for(OrbitalElement.SemiMajorAxis)
    print(f"SMA 1-sigma = {sigma_sma_km:.3} km")

    # Build an Ephemeris
    eme2k = almanac.frame_info(Frames.EARTH_J2000)
    epoch = Epoch("2024-02-29T12:34:56")

    orbit = Orbit.from_keplerian_altitude(
        567.8, 1e-4, 28.5, 75.0, 115.0, 0.0, epoch, eme2k
    )

    ts = TimeSeries(epoch, epoch + Unit.Day * 1, Unit.Minute * 1, True)

    records = []
    ephem_from_empty = Ephemeris([], "My Spacecraft")

    for tickytack in ts:
        orbit_t = orbit.at_epoch(tickytack)
        cov = Covariance(np.diag([1e3] * 6), LocalFrame.RIC)
        record = EphemerisRecord(orbit_t, cov)
        records += [record]
        ephem_from_empty.insert_orbit(orbit_t)
    # Add an entry one tiny step later
    final_orbit = orbit.at_epoch(records[-1].orbit.epoch + Unit.Nanosecond * 4)
    ephem_from_empty.insert_orbit(final_orbit)

    ephem_from_list = Ephemeris([rcrd.orbit for rcrd in records], "My Spacecraft Too!")
    ephem_from_list.insert_orbit(final_orbit)

    assert ephem_from_list.start_epoch() == ephem_from_empty.start_epoch()
    assert ephem_from_list.end_epoch() == ephem_from_empty.end_epoch()
    assert ephem_from_list.len() == ephem_from_empty.len()

```

#### `anise-py/tests/test_analysis.py`

```python
from anise import (
    Almanac,
    Aberration,
    LocationDhallSet,
    LocationDhallSetEntry,
)
from anise.astro import Location, TerrainMask, FrameUid
from anise.analysis import Event, Condition
import anise.analysis as analysis
from anise.time import Duration, Epoch, TimeSeries, Unit
from anise.constants import Frames
from anise.astro import Frame
from pathlib import Path
from sys import platform


def test_analysis_gen_report():
    """
    Tests the generation of a scalar report with complex, nested expressions.
    """

    data_path = Path(__file__).parent.joinpath("..", "..", "data")
    almanac = (
        Almanac(str(data_path.joinpath("de440s.bsp")))
        .load(str(data_path.joinpath("pck08.pca")))
        .load(str(data_path.joinpath("lro.bsp")))
    )
    almanac.describe(spk=True)

    target_frame = analysis.FrameSpec.Loaded(Frames.EME2000)
    observer_frame = analysis.FrameSpec.Loaded(Frames.MOON_J2000)

    state = analysis.StateSpec(
        target_frame=target_frame,
        observer_frame=observer_frame,
        ab_corr=None,
    )

    # Build the orthogonal VNC frame of the Earth...Moon orbit
    vnc = analysis.OrthogonalFrame.XY(
        x=analysis.VectorExpr.Unit(analysis.VectorExpr.Velocity(state)),
        y=analysis.VectorExpr.Unit(analysis.VectorExpr.OrbitalMomentum(state)),
    )

    sun_state = analysis.StateSpec(
        target_frame=target_frame,
        observer_frame=analysis.FrameSpec.Loaded(Frames.SUN_J2000),
        ab_corr=Aberration("LT"),
    )

    # Project the Earth->Sun vector onto the VNC frame
    proj = analysis.VectorExpr.Project(
        v=analysis.VectorExpr.Negate(
            analysis.VectorExpr.Unit(analysis.VectorExpr.Radius(sun_state))
        ),
        frame=vnc,
        plane=analysis.Plane.XY,
    )

    # Rebuild the Local Solar Time calculation from fundamental expressions
    earth_sun = analysis.StateSpec(
        target_frame=analysis.FrameSpec.Loaded(Frames.SUN_J2000),
        observer_frame=observer_frame,
        ab_corr=Aberration("LT"),
    )
    u = analysis.VectorExpr.Unit(
        analysis.VectorExpr.CrossProduct(
            a=analysis.VectorExpr.Unit(analysis.VectorExpr.Radius(earth_sun)),
            b=analysis.VectorExpr.Unit(analysis.VectorExpr.OrbitalMomentum(state)),
        )
    )
    v = analysis.VectorExpr.CrossProduct(
        a=analysis.VectorExpr.Unit(analysis.VectorExpr.OrbitalMomentum(state)), b=u
    )
    r = analysis.VectorExpr.Radius(state)
    sin_theta = analysis.ScalarExpr.DotProduct(a=v, b=r)
    cos_theta = analysis.ScalarExpr.DotProduct(a=u, b=r)
    theta = analysis.ScalarExpr.Atan2(y=sin_theta, x=cos_theta)
    lst_prod = analysis.ScalarExpr.Mul(
        a=analysis.ScalarExpr.Mul(a=theta, b=analysis.ScalarExpr.Constant(1.0 / 180.0)),
        b=analysis.ScalarExpr.Constant(12.0),
    )
    lst_add = analysis.ScalarExpr.Add(a=lst_prod, b=analysis.ScalarExpr.Constant(6.0))
    lst = analysis.ScalarExpr.Modulo(v=lst_add, m=analysis.ScalarExpr.Constant(24.0))

    # Define all scalars to be calculated
    scalars = [
        analysis.ScalarExpr.Element(analysis.OrbitalElement.SemiMajorAxis),
        analysis.ScalarExpr.Element(analysis.OrbitalElement.Eccentricity),
        analysis.ScalarExpr.Element(analysis.OrbitalElement.Rmag),
        # IMPORTANT: Enums that do not have arguments MUST be called with ()
        # Otherwise PyO3 (the bindings) initializes them differently.
        # This causes a 'type' cannot be converted to ScalarExpr error!
        analysis.ScalarExpr.BetaAngle(),
        analysis.ScalarExpr.SolarEclipsePercentage(eclipsing_frame=Frames.VENUS_J2000),
        analysis.ScalarExpr.Norm(analysis.VectorExpr.Radius(state)),
        analysis.ScalarExpr.DotProduct(
            a=analysis.VectorExpr.EccentricityVector(state),
            b=analysis.VectorExpr.Fixed(x=1.0, y=0.0, z=0.0),
        ),
        analysis.ScalarExpr.VectorX(analysis.VectorExpr.EccentricityVector(state)),
        analysis.ScalarExpr.VectorY(analysis.VectorExpr.EccentricityVector(state)),
        analysis.ScalarExpr.VectorZ(analysis.VectorExpr.EccentricityVector(state)),
        analysis.ScalarExpr.Norm(
            analysis.VectorExpr.CrossProduct(
                a=analysis.VectorExpr.Radius(state),
                b=analysis.VectorExpr.Velocity(state),
            )
        ),
        analysis.ScalarExpr.Element(analysis.OrbitalElement.Hmag),
        analysis.ScalarExpr.AngleBetween(
            a=analysis.VectorExpr.Radius(state), b=analysis.VectorExpr.Velocity(state)
        ),
        analysis.ScalarExpr.AzimuthFromLocation(location_id=123, obstructing_body=None),
        analysis.ScalarExpr.ElevationFromLocation(
            location_id=123, obstructing_body=None
        ),
        analysis.ScalarExpr.RangeFromLocation(location_id=123, obstructing_body=None),
        analysis.ScalarExpr.RangeRateFromLocation(
            location_id=123, obstructing_body=None
        ),
        analysis.ScalarExpr.LocalTimeAscNode(),
        analysis.ScalarExpr.LocalTimeDescNode(),
        analysis.ScalarExpr.VectorX(proj),
        analysis.ScalarExpr.VectorY(proj),
        analysis.ScalarExpr.VectorZ(proj),
        analysis.ScalarExpr.LocalSolarTime(),
        lst,  # Our custom LST calculation
    ]

    # Test S-Expression serialization/deserialization
    proj_s_expr = scalars[-1].to_s_expr()
    assert len(proj_s_expr) > 0

    # Add aliases to some of the scalars for the report header
    scalars_with_aliases = [(s, None) for s in scalars]
    scalars_with_aliases[-5] = (scalars_with_aliases[-5][0], "proj VNC X")
    scalars_with_aliases[-4] = (scalars_with_aliases[-4][0], "proj VNC Y")
    scalars_with_aliases[-3] = (scalars_with_aliases[-3][0], "proj VNC Z")
    scalars_with_aliases[-1] = (scalars_with_aliases[-1][0], "LST (h)")

    # Build the final report object
    report = analysis.ReportScalars(scalars_with_aliases, state)

    # Test report serialization
    report_s_expr = report.to_s_expr()
    report_reloaded = analysis.ReportScalars.from_s_expr(report_s_expr)
    assert report_reloaded.to_s_expr() == report_s_expr

    # Generate the report data
    series = TimeSeries(
        Epoch("2025-01-01 00:00:00 UTC"),
        Epoch("2025-01-02 12:00:00 UTC"),
        Unit.Day * 0.5,
        inclusive=True,
    )
    data = almanac.report_scalars(report, series)

    assert len(data) == 4
    last_row = data["2025-01-02T12:00:00.000000"]
    assert len(last_row) == len(scalars_with_aliases)

    # Validate some computed values
    assert (
        last_row["Hmag (km)"]
        == last_row[
            "|Radius(Earth J2000 -> Moon J2000) тип Velocity(Earth J2000 -> Moon J2000)|"
        ]
    )

    # Check that our manual LST is close to the built-in one
    time_diff = abs(last_row["LST (h)"] - last_row["local solar time (h)"])
    assert time_diff < (Unit.Second * 1).to_unit(Unit.Hour)

    # Check that the projections are valid (components of a unit vector)
    for col_name, value in last_row.items():
        if "proj" in col_name:
            assert abs(value) <= 1.0


def test_analysis_event():
    """
    Tests event finding for apoapsis, periapsis, eclipses, and other criteria.
    """
    if platform == "win32":
        return True
    data_path = Path(__file__).parent.joinpath("..", "..", "data")
    almanac = (
        Almanac(str(data_path.joinpath("de440s.bsp")))
        .load(str(data_path.joinpath("pck08.pca")))
        .load(str(data_path.joinpath("lro.bsp")))
    )

    lro_frame = Frame(-85, 1)  # LRO NAIF ID

    lro_state_spec = analysis.StateSpec(
        target_frame=analysis.FrameSpec.Loaded(lro_frame),
        observer_frame=analysis.FrameSpec.Loaded(Frames.MOON_J2000),
        ab_corr=None,
    )

    # Define several event criteria
    sun_has_set = analysis.Event(
        analysis.ScalarExpr.SunAngle(observer_id=-85),
        Condition.LessThan(90.0),
        Unit.Second * 0.5,
        ab_corr=None,
    )
    apolune = Event.apoapsis()
    perilune = Event.periapsis()
    eclipse = Event.total_eclipse(Frames.MOON_J2000)
    eclipse_boundary = Event(
        eclipse.scalar, Condition.Equals(99.0), eclipse.epoch_precision, None
    )

    # Test event serialization
    eclipse_s_expr = eclipse.to_s_expr()
    deserialized_eclipse = analysis.Event.from_s_expr(eclipse_s_expr)
    assert deserialized_eclipse.to_s_expr() == eclipse_s_expr

    # Get the time domain for LRO from the loaded ephemeris
    start_epoch, end_epoch = almanac.spk_domain(-85)
    start_orbit = almanac.transform(lro_frame, Frames.MOON_J2000, start_epoch, None)
    period = start_orbit.period()

    # Find apoapsis events
    apo_events = almanac.report_events(lro_state_spec, apolune, start_epoch, end_epoch)
    for event in apo_events:
        ta_deg = event.orbit.ta_deg()
        assert abs(ta_deg - 180.0) < 1e-2

    # Find periapsis events
    peri_events = almanac.report_events(
        lro_state_spec, perilune, start_epoch, end_epoch
    )
    for event in peri_events:
        ta_deg = event.orbit.ta_deg()
        assert ta_deg < 1e-2 or abs(ta_deg - 360.0) < 1e-2

    # Check that we found one apoapsis/periapsis per orbit
    dts_apo = [
        s.orbit.epoch.timedelta(f.orbit.epoch)
        for f, s in zip(apo_events[:-1], apo_events[1:])
    ]
    assert all((dt - period).abs() < Unit.Minute * 5 for dt in dts_apo)

    dts_peri = [
        s.orbit.epoch.timedelta(f.orbit.epoch)
        for f, s in zip(peri_events[:-1], peri_events[1:])
    ]
    assert all((dt - period).abs() < Unit.Minute * 5 for dt in dts_peri)

    tick = Epoch.system_now()
    # Find sunset/sunrise arcs
    sunset_arcs = almanac.report_event_arcs(
        lro_state_spec, sun_has_set, start_epoch, end_epoch
    )
    print(
        f"{len(sunset_arcs)} sunset arcs found in {Epoch.system_now().timedelta(tick)}"
    )
    assert sunset_arcs[1].rise.edge == analysis.EventEdge.Falling
    assert sunset_arcs[1].fall.edge == analysis.EventEdge.Rising
    assert len(sunset_arcs) == 452

    # Find eclipse arcs in a short time span
    tick = Epoch.system_now()
    eclipse_arcs = almanac.report_event_arcs(
        lro_state_spec, eclipse, start_epoch, start_epoch + period * 3
    )
    assert len(eclipse_arcs) == 3
    print("Eclipse arcs found in ", Epoch.system_now().timedelta(tick))

    # Validate the eclipse periods
    for arc in eclipse_arcs:
        assert Unit.Minute * 24 < arc.duration() < Unit.Minute * 40

        # Check points in and around the arc to confirm the event state
        series = TimeSeries(
            arc.start_epoch() - eclipse.epoch_precision,
            arc.end_epoch() + eclipse.epoch_precision,
            Unit.Minute * 0.5,
            inclusive=True,
        )
        for epoch in series:
            orbit = lro_state_spec.evaluate(epoch, almanac)
            # IMPORTANT: Eclipse is not defined as a Condition.Equal
            # so it cannot be used as-is for an `eval` check.
            # Instead we use the eclipse boundary. That's how's the internals work.
            eclipse_val = eclipse_boundary.eval(orbit, almanac)
            is_in_eclipse = eclipse_val >= 0.0

            if arc.start_epoch() <= epoch < arc.end_epoch():
                assert is_in_eclipse, (
                    f"Epoch {epoch} should be in eclipse: {eclipse_val}: {arc}"
                )
            else:
                # Outside the arc, it should not be in eclipse, or it's a falling value
                assert not is_in_eclipse or eclipse_val < 0.0


def test_location_accesses():
    """
    Demonstrate building a Location Dhall file, loading it into the Almanac, reporting the access times.
    """
    if platform == "win32":
        return True

    mask = [TerrainMask(0.0, 5.0), TerrainMask(35.0, 10.0), TerrainMask(270.0, 3.0)]
    dss65 = Location(
        40.427_222,
        4.250_556,
        0.834_939,
        FrameUid(399, 399),
        mask,
        terrain_mask_ignored=True,
    )

    # To build a location data set kernel, we must first build a location dhall set entry
    entry = LocationDhallSetEntry(dss65, id=1, alias="My Alias")
    # Then we append it to a LocationDhallSet
    dhallset = LocationDhallSet([entry])
    assert "data" in dir(dhallset), "missing getting on dhall set"
    # Now, we can build the kernel
    dataset = dhallset.to_dataset()
    # Save it as a Location Kernel ANISE (LKA) file, overwritting it if it exists
    dataset.save_as("pytest_loc_kernel_report.lka", True)
    data_path = Path(__file__).parent.joinpath("..", "..", "data")
    almanac = (
        Almanac(str(data_path.joinpath("de440s.bsp")))
        .load(str(data_path.joinpath("pck08.pca")))
        .load(str(data_path.joinpath("lro.bsp")))
        .load("pytest_loc_kernel_report.lka")
    )
    # Only print the loaded location info
    almanac.describe(locations=True)

    # Build the horizon event
    horizon = Event.visible_from_location_id(1)

    lro_frame = Frame(-85, 1)  # LRO NAIF ID
    start_epoch, _end_epoch = almanac.spk_domain(-85)

    lro_state_spec = analysis.StateSpec(
        target_frame=analysis.FrameSpec.Loaded(lro_frame),
        observer_frame=analysis.FrameSpec.Loaded(Frames.MOON_J2000),
        ab_corr=None,
    )

    tick = Epoch.system_now()
    comm_arcs = almanac.report_event_arcs(
        lro_state_spec, horizon, start_epoch, start_epoch + Unit.Day * 3
    )
    print(f"{len(comm_arcs)} Comm arcs found in ", Epoch.system_now().timedelta(tick))

    series = TimeSeries(
        start_epoch,
        start_epoch + Unit.Day * 3,
        Unit.Minute * 0.5,
        inclusive=True,
    )

    for arc in comm_arcs:
        # Check points in and around the arc to confirm the event state
        series = TimeSeries(
            arc.start_epoch() - horizon.epoch_precision,
            arc.end_epoch() + horizon.epoch_precision,
            Unit.Minute * 0.5,
            inclusive=True,
        )
        for epoch in series:
            orbit = lro_state_spec.evaluate(epoch, almanac)
            aer = almanac.azimuth_elevation_range_sez_from_location_name(
                orbit, "My Alias"
            )
            is_visible = aer.elevation_deg > 0.0

            if arc.start_epoch() <= epoch < arc.end_epoch():
                assert is_visible, f"Epoch {epoch} should be visible"
            else:
                assert not is_visible

    # Check visibility arc function
    visibility_arcs = almanac.report_visibility_arcs(
        lro_state_spec,
        1,
        start_epoch,
        start_epoch + Unit.Day * 3,
        Unit.Minute * 10,
        None,
    )
    first_pass = visibility_arcs[0]
    assert first_pass.duration().round(Unit.Second * 1) == Duration("8 h 56 min 55 s")
    # Visibility Arc contains the location reference info for pretty printing
    print(first_pass.location_ref)
    # And the location data itself
    print(first_pass.location, first_pass.location.height_km)
    # AER data is a list of AzElRange objects
    assert len(first_pass.aer_data) == 54
    assert abs(first_pass.aer_data[0].elevation_deg - 1e-11) < 1e-11, (
        "elevation should be nearly zero"
    )


```
